{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates as denormalize_coordinates\n",
    "\n",
    "from filterpy.kalman import KalmanFilter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n",
    "# flatten and remove duplicates\n",
    "all_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n",
    " \n",
    "# Landmark points corresponding to right eye\n",
    "all_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\n",
    "all_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n",
    " \n",
    "# Combined for plotting - Landmark points for both eye\n",
    "all_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n",
    " \n",
    "# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\n",
    "chosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\n",
    "chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
    "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point_1, point_2):\n",
    "    \"\"\"Calculate l2-norm between two points\"\"\"\n",
    "    dist = sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "    try:\n",
    "        # Compute the euclidean distance between the horizontal\n",
    "        coords_points = []\n",
    "        for i in refer_idxs:\n",
    "            lm = landmarks[i]\n",
    "            coord = denormalize_coordinates(lm.x, lm.y, \n",
    "                                             frame_width, frame_height)\n",
    "            coords_points.append(coord)\n",
    " \n",
    "        # Eye landmark (x, y)-coordinates\n",
    "        P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "        P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "        P1_P4 = distance(coords_points[0], coords_points[3])\n",
    " \n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    " \n",
    "    except:\n",
    "        ear = 0.0\n",
    "        coords_points = None\n",
    " \n",
    "    return ear, coords_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "    \"\"\"Calculate Eye aspect ratio\"\"\"\n",
    " \n",
    "    left_ear, left_lm_coordinates = get_ear(\n",
    "                                      landmarks, \n",
    "                                      left_eye_idxs, \n",
    "                                      image_w, \n",
    "                                      image_h\n",
    "                                    )\n",
    "    right_ear, right_lm_coordinates = get_ear(\n",
    "                                      landmarks, \n",
    "                                      right_eye_idxs, \n",
    "                                      image_w, \n",
    "                                      image_h\n",
    "                                    )\n",
    "    Avg_EAR = (left_ear + right_ear) / 2.0\n",
    " \n",
    "    return Avg_EAR, (left_lm_coordinates, right_lm_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mediapipe_app(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    " ):\n",
    "    \"\"\"Initialize and return Mediapipe FaceMesh Solution Graph object\"\"\"\n",
    "    face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "        max_num_faces=max_num_faces,\n",
    "        refine_landmarks=refine_landmarks,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    " \n",
    "    return face_mesh\n",
    " \n",
    "def plot_eye_landmarks(frame, left_lm_coordinates, \n",
    "                       right_lm_coordinates, color\n",
    "                       ):\n",
    "    for lm_coordinates in [left_lm_coordinates, right_lm_coordinates]:\n",
    "        if lm_coordinates:\n",
    "            for coord in lm_coordinates:\n",
    "                cv2.circle(frame, coord, 2, color, -1)\n",
    " \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    return frame\n",
    " \n",
    " \n",
    "def plot_text(image, text, origin, \n",
    "              color, font=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "              fntScale=0.8, thickness=2\n",
    "              ):\n",
    "    image = cv2.putText(image, text, origin, font, fntScale, color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFrameHandler:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the necessary constants, mediapipe app\n",
    "        and tracker variables\n",
    "        \"\"\"\n",
    "        # Left and right eye chosen landmarks.\n",
    "        self.eye_idxs = {\n",
    "            \"left\": [362, 385, 387, 263, 373, 380],\n",
    "            \"right\": [33, 160, 158, 133, 153, 144],\n",
    "        }\n",
    " \n",
    "        # Used for coloring landmark points.\n",
    "        # Its value depends on the current EAR value.\n",
    "        self.RED = (0, 0, 255)  # BGR\n",
    "        self.GREEN = (0, 255, 0)  # BGR\n",
    " \n",
    "        # Initializing Mediapipe FaceMesh solution pipeline\n",
    "        self.facemesh_model = get_mediapipe_app()\n",
    " \n",
    "        # For tracking counters and sharing states in and out of callbacks.\n",
    "        self.state_tracker = {\n",
    "            \"start_time\": time.perf_counter(),\n",
    "            \"DROWSY_TIME\": 0.0,  # Holds time passed with EAR < EAR_THRESH\n",
    "            \"COLOR\": self.GREEN,\n",
    "            \"play_alarm\": False,\n",
    "        }\n",
    " \n",
    "        self.EAR_txt_pos = (10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(self, frame: np.array, thresholds: dict):\n",
    " \n",
    "        # To improve performance,\n",
    "        # mark the frame as not writeable to pass by reference.\n",
    "        frame.flags.writeable = False\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        DROWSY_TIME_txt_pos = (10, int(frame_h // 2 * 1.7))\n",
    "        ALM_txt_pos = (10, int(frame_h // 2 * 1.85))\n",
    " \n",
    "        results = self.facemesh_model.process(frame)\n",
    " \n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0].landmark\n",
    "            EAR, coordinates = calculate_avg_ear(landmarks,\n",
    "                                                 self.eye_idxs[\"left\"], \n",
    "                                                 self.eye_idxs[\"right\"], \n",
    "                                                 frame_w, \n",
    "                                                 frame_h\n",
    "                                                 )\n",
    "            frame = plot_eye_landmarks(frame, \n",
    "                                       coordinates[0], \n",
    "                                       coordinates[1],\n",
    "                                       self.state_tracker[\"COLOR\"]\n",
    "                                       )\n",
    " \n",
    "            if EAR < thresholds[\"EAR_THRESH\"]:\n",
    " \n",
    "                # Increase DROWSY_TIME to track the time period with \n",
    "                # EAR less than the threshold\n",
    "                # and reset the start_time for the next iteration.\n",
    "                end_time = time.perf_counter()\n",
    " \n",
    "                self.state_tracker[\"DROWSY_TIME\"] += end_time - self.state_tracker[\"start_time\"]\n",
    "                self.state_tracker[\"start_time\"] = end_time\n",
    "                self.state_tracker[\"COLOR\"] = self.RED\n",
    " \n",
    "                if self.state_tracker[\"DROWSY_TIME\"] >= thresholds[\"WAIT_TIME\"]:\n",
    "                    self.state_tracker[\"play_alarm\"] = True\n",
    "                    plot_text(frame, \"WAKE UP! WAKE UP\", \n",
    "                              ALM_txt_pos, self.state_tracker[\"COLOR\"])\n",
    " \n",
    "            else:\n",
    "                self.state_tracker[\"start_time\"] = time.perf_counter()\n",
    "                self.state_tracker[\"DROWSY_TIME\"] = 0.0\n",
    "                self.state_tracker[\"COLOR\"] = self.GREEN\n",
    "                self.state_tracker[\"play_alarm\"] = False\n",
    " \n",
    "            EAR_txt = f\"EAR: {round(EAR, 2)}\"\n",
    "            DROWSY_TIME_txt = f\"DROWSY: {round(self.state_tracker['DROWSY_TIME'], 3)} Secs\"\n",
    "            plot_text(frame, EAR_txt, \n",
    "                      self.EAR_txt_pos, self.state_tracker[\"COLOR\"])\n",
    "            plot_text(frame, DROWSY_TIME_txt, \n",
    "                      DROWSY_TIME_txt_pos, self.state_tracker[\"COLOR\"])\n",
    " \n",
    "        else:\n",
    "            self.state_tracker[\"start_time\"] = time.perf_counter()\n",
    "            self.state_tracker[\"DROWSY_TIME\"] = 0.0\n",
    "            self.state_tracker[\"COLOR\"] = self.GREEN\n",
    "            self.state_tracker[\"play_alarm\"] = False\n",
    " \n",
    "            # Flip the frame horizontally for a selfie-view display.\n",
    "            frame = cv2.flip(frame, 1)\n",
    " \n",
    "        return frame, self.state_tracker[\"play_alarm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    *,\n",
    "    img_dt,\n",
    "    img_eye_lmks=None,\n",
    "    img_eye_lmks_chosen=None,\n",
    "    face_landmarks=None,\n",
    "    ts_thickness=1,\n",
    "    ts_circle_radius=2,\n",
    "    lmk_circle_radius=3,\n",
    "    name=\"1\",\n",
    "):\n",
    "    # For plotting Face Tessellation\n",
    "    image_drawing_tool = img_dt \n",
    "\n",
    "    # For plotting all eye landmarks\n",
    "    image_eye_lmks = img_dt.copy() if img_eye_lmks is None else img_eye_lmks\n",
    "\n",
    "    # For plotting chosen eye landmarks\n",
    "    img_eye_lmks_chosen = img_dt.copy() if img_eye_lmks_chosen is None else img_eye_lmks_chosen\n",
    "\n",
    "    # Initializing drawing utilities for plotting face mesh tessellation\n",
    "    connections_drawing_spec = mp_drawing.DrawingSpec(\n",
    "    thickness=ts_thickness, \n",
    "    circle_radius=ts_circle_radius, \n",
    "    color=(255, 255, 255)\n",
    "    )\n",
    "\n",
    "    # Initialize a matplotlib figure.\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.set_facecolor(\"white\")\n",
    "\n",
    "    # Draw landmarks on face using the drawing utilities.\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=image_drawing_tool,\n",
    "        landmark_list=face_landmarks,\n",
    "        connections=mp_facemesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=connections_drawing_spec,\n",
    "    )\n",
    "\n",
    "    # Get the object which holds the x, y, and z coordinates for each landmark\n",
    "    landmarks = face_landmarks.landmark\n",
    "\n",
    "    # Iterate over all landmarks.\n",
    "    # If the landmark_idx is present in either all_idxs or all_chosen_idxs,\n",
    "    # get the denormalized coordinates and plot circles at those coordinates.\n",
    " \n",
    "    for landmark_idx, landmark in enumerate(landmarks):\n",
    "        if landmark_idx in all_idxs:\n",
    "            pred_cord = denormalize_coordinates(landmark.x, \n",
    "                                                landmark.y, \n",
    "                                                imgW, imgH)\n",
    "            cv2.circle(image_eye_lmks, \n",
    "                        pred_cord, \n",
    "                        lmk_circle_radius, \n",
    "                        (255, 255, 255), \n",
    "                        -1\n",
    "                        )\n",
    "\n",
    "        if landmark_idx in all_chosen_idxs:\n",
    "            pred_cord = denormalize_coordinates(landmark.x, \n",
    "                                                landmark.y, \n",
    "                                                imgW, imgH)\n",
    "            cv2.circle(img_eye_lmks_chosen, \n",
    "                        pred_cord, \n",
    "                        lmk_circle_radius, \n",
    "                        (255, 255, 255), \n",
    "                        -1\n",
    "                        )\n",
    "\n",
    "    # Plot post-processed images\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Face Mesh Tessellation\", fontsize=18)\n",
    "    plt.imshow(image_drawing_tool)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"All eye landmarks\", fontsize=18)\n",
    "    plt.imshow(image_eye_lmks)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img_eye_lmks_chosen)\n",
    "    plt.title(\"Chosen landmarks\", fontsize=18)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_eyes_open  = cv2.imread(\"test-open-eyes.jpg\")[:, :, ::-1]\n",
    "image_eyes_close = cv2.imread(\"test-close-eyes.jpg\")[:, :, ::-1]\n",
    " \n",
    "for idx, image in enumerate([image_eyes_open, image_eyes_close]):\n",
    "    \n",
    "    image = np.ascontiguousarray(image)\n",
    "    imgH, imgW, _ = image.shape\n",
    " \n",
    "    # Creating a copy of the original image for plotting the EAR value\n",
    "    custom_chosen_lmk_image = image.copy()\n",
    " \n",
    "    # Running inference using static_image_mode\n",
    "    with mp_facemesh.FaceMesh(refine_landmarks=True) as face_mesh:\n",
    "        results = face_mesh.process(image).multi_face_landmarks\n",
    " \n",
    "        # If detections are available.\n",
    "        if results:\n",
    "            for face_id, face_landmarks in enumerate(results):\n",
    "                landmarks = face_landmarks.landmark\n",
    "                EAR, _ = calculate_avg_ear(\n",
    "                          landmarks, \n",
    "                          chosen_left_eye_idxs, \n",
    "                          chosen_right_eye_idxs, \n",
    "                          imgW, \n",
    "                          imgH\n",
    "                      )\n",
    " \n",
    "                # Print the EAR value on the custom_chosen_lmk_image.\n",
    "                cv2.putText(custom_chosen_lmk_image, \n",
    "                            f\"EAR: {round(EAR, 2)}\", (1, 24),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, \n",
    "                            0.9, (255, 255, 255), 2\n",
    "                )                \n",
    "              \n",
    "                plot(img_dt=image.copy(),\n",
    "                     img_eye_lmks_chosen=custom_chosen_lmk_image,\n",
    "                     face_landmarks=face_landmarks,\n",
    "                     ts_thickness=1, \n",
    "                     ts_circle_radius=3, \n",
    "                     lmk_circle_radius=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_facemesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      continue\n",
    "    \n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_facemesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_facemesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "            \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_facemesh.FACEMESH_IRISES,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "    cv2.imshow('MediaPipe Face Mesh', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "'''\n",
    "    if results.face_landmarks:\n",
    "      face_landmarks = results.face_landmarks\n",
    "      face_data = update(face_landmarks)\n",
    "\n",
    "      print(face_data[\"eye_aspect_ratio\"][\"left\"], face_data[\"eye_aspect_ratio\"][\"right\"])\n",
    "'''\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parameters = 11\n",
    "\n",
    "def __init__(self):\n",
    "    \n",
    "        self.filter = KalmanFilter(dim_x=self.n_parameters*2, dim_z=self.n_parameters)\n",
    "        self.filter.x = np.zeros(self.n_parameters*2)\n",
    "        self.filter.F = np.identity(self.n_parameters*2)\n",
    "        for i in range(self.n_parameters):\n",
    "            self.filter.F[i, i+self.n_parameters] = 1\n",
    "        self.filter.H \\\n",
    "            = np.concatenate((np.identity(self.n_parameters), np.zeros((self.n_parameters, self.n_parameters))), axis=1)\n",
    "\n",
    "        # EAR\n",
    "        self.filter.Q[6:8, 6:8] *= 0.1\n",
    "        self.filter.Q[self.n_parameters+6:self.n_parameters+8, self.n_parameters+6:self.n_parameters+8] *= 0.1\n",
    "        # MAR\n",
    "        self.filter.Q[10:11, 10:11] *= 1\n",
    "        self.filter.Q[self.n_parameters + 10:self.n_parameters + 11, self.n_parameters + 10:self.n_parameters + 11] *= 0.1\n",
    "\n",
    "        \n",
    "        # EAR\n",
    "        self.filter.R[6:8, 6:8] *= 7\n",
    "        # MAR\n",
    "        self.filter.R[10:11, 10:11] *= 0.01\n",
    "\n",
    "def update(self, face_landmarks):\n",
    "        self.filter.predict()\n",
    "\n",
    "        face_data = extract_data(face_landmarks)\n",
    "\n",
    "        self.filter.update([\n",
    "            face_data['eye_aspect_ratio']['left'],\n",
    "            face_data['eye_aspect_ratio']['right'],\n",
    "        ])\n",
    "        \n",
    "        face_data['eye_aspect_ratio']['left'], face_data['eye_aspect_ratio']['right']= self.filter.x[:self.n_parameters]\n",
    "        \n",
    "        return face_data\n",
    "\n",
    "\n",
    "def extract_data(face_landmarks):\n",
    "    face_data = {\n",
    "        \"eye_aspect_ratio\": {\n",
    "            \"left\": 0,\n",
    "            \"right\": 0\n",
    "        }        \n",
    "    }\n",
    "\n",
    "    landmarks = face_landmarks.landmark\n",
    "\n",
    "    left_eye_landmarks = [\n",
    "        landmarks[33],\n",
    "        landmarks[159],\n",
    "        landmarks[158],\n",
    "        landmarks[133],\n",
    "        landmarks[145]\n",
    "    ]\n",
    "    right_eye_landmarks = [\n",
    "        landmarks[263],\n",
    "        landmarks[386],\n",
    "        landmarks[385],\n",
    "        landmarks[362],\n",
    "        landmarks[374]\n",
    "    ]\n",
    "    \n",
    "    face_data[\"eye_aspect_ratio\"][\"left\"], face_data[\"eye_aspect_ratio\"][\"right\"] = eye_parameters(left_eye_landmarks, right_eye_landmarks)\n",
    "\n",
    "    # face_data[\"mouth_aspect_ratio\"] = mouth_aspect_ratio(mouth_landmarks)\n",
    "    return face_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_parameters(left_eye_landmarks, right_eye_landmarks):\n",
    "\n",
    "    eye_aspect_ratios = [None, None]\n",
    "\n",
    "    for i, (eye_landmarks) in enumerate(zip(left_eye_landmarks, right_eye_landmarks)):\n",
    "        \n",
    "        outer, top_outer, top_inner, inner, bottom, iris \\\n",
    "            = map(lambda p: np.array([p.x, p.y, p.z]), (*eye_landmarks, iris))\n",
    "        top = (top_outer + top_inner) / 2\n",
    "\n",
    "        eye_aspect_ratios[i] = eye_aspect_ratio(outer, inner, top, bottom)\n",
    "    \n",
    "    return eye_aspect_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate eye aspect ratio\n",
    "def eye_aspect_ratio(outer, inner, top, bottom):\n",
    "    SCALING_FACTOR = 1\n",
    "    return np.clip(np.linalg.norm(top - bottom) / np.linalg.norm(outer - inner) * SCALING_FACTOR, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.face_landmarks:\n",
    "    face_landmarks = results.face_landmarks\n",
    "    face_data = update(face_landmarks)\n",
    "\n",
    "    print(face_data[\"eye_aspect_ratio\"][\"left\"], face_data[\"eye_aspect_ratio\"][\"right\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b993bb36e24ddcd96a4fb3a8aad47b6369c3dee68b732e93d03e2f56cb99010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
