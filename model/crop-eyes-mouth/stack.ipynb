{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouthModel = keras.models.load_model(\"../cnn-mouth/base_cropped_yawning_model.h5\")\n",
    "eyesModel = keras.models.load_model(\"../cnn-eyes/base_eyes_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouth_cropper(path):\n",
    "    image = face_recognition.load_image_file(path)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    if face_landmarks_list:\n",
    "        try:\n",
    "            mouth = face_landmarks_list[0]['bottom_lip'] + face_landmarks_list[0]['top_lip']\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "        x_coords = [coord[0] for coord in mouth]\n",
    "        y_coords = [coord[1] for coord in mouth]\n",
    "\n",
    "        left = min(x_coords)\n",
    "        top = min(y_coords)\n",
    "        right = max(x_coords)\n",
    "        bottom = max(y_coords)\n",
    "\n",
    "        im = Image.open(path)\n",
    "        im = im.crop((left, top, right, bottom))\n",
    "\n",
    "        im = im.resize((80, 80))\n",
    "\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_cropper(path):\n",
    "    image = face_recognition.load_image_file(path)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    eyes = []\n",
    "    ans = []\n",
    "    try:\n",
    "        eyes.append(face_landmarks_list[0]['left_eye'])\n",
    "        eyes.append(face_landmarks_list[0]['right_eye'])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    for eye in eyes:\n",
    "        x_max = max([coordinate[0] for coordinate in eye])\n",
    "        x_min = min([coordinate[0] for coordinate in eye])\n",
    "        y_max = max([coordinate[1] for coordinate in eye])\n",
    "        y_min = min([coordinate[1] for coordinate in eye])\n",
    "        # establish the range of x and y coordinates    \n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        \n",
    "        # to make sure the full eye is captured,\n",
    "        # calculate the coordinates of a square that has 50%\n",
    "        # cushion added to the axis with a larger range\n",
    "        if x_range > y_range:\n",
    "            right = round(.5*x_range) + x_max\n",
    "            left = x_min - round(.5*x_range)\n",
    "            bottom = round(((right-left) - y_range))/2 + y_max\n",
    "            top = y_min - round(((right-left) - y_range))/2\n",
    "        else:\n",
    "            bottom = round(.5*y_range) + y_max\n",
    "            top = y_min - round(.5*y_range)\n",
    "            right = round(((bottom-top) - x_range))/2 + x_max\n",
    "            left = x_min - round(((bottom-top) - x_range))/2\n",
    "        \n",
    "        #crop original image using the cushioned coordinates\n",
    "        im = Image.open(path)\n",
    "        im = im.crop((left, top, right, bottom))\n",
    "        \n",
    "        # resize image for input into our model\n",
    "        im = im.resize((80,80))\n",
    "        ans.append(im)\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/test/mouth/Normal/327867760_594764842492235_1868613635924958884_n.jpg\n",
      "../data/test/mouth/Normal/328850083_731856778560861_9036283887921550214_n.jpg\n",
      "../data/test/mouth/Normal/328908713_1401687160648422_2500127038507218711_n.jpg\n",
      "../data/test/mouth/Normal/IMG-4711.jpg\n",
      "../data/test/mouth/Normal/IMG-4712.jpg\n",
      "../data/test/mouth/Normal/IMG-4713.jpg\n",
      "../data/test/mouth/Normal/IMG-4714.jpg\n",
      "../data/test/mouth/Normal/IMG-4715.jpg\n",
      "../data/test/mouth/Normal/IMG-4716.jpg\n",
      "../data/test/mouth/Normal/IMG-4727 (1).jpg\n",
      "../data/test/mouth/Normal/IMG-4728.jpg\n",
      "../data/test/mouth/Normal/IMG-4729.jpg\n",
      "../data/test/mouth/Normal/IMG_0155.jpg\n",
      "../data/test/mouth/Normal/IMG_0156.jpg\n",
      "../data/test/mouth/Normal/IMG_0157.jpg\n",
      "../data/test/mouth/Normal/IMG_0158.jpg\n",
      "../data/test/mouth/Normal/IMG_0159.jpg\n",
      "../data/test/mouth/Normal/IMG_0794.jpg\n",
      "../data/test/mouth/Normal/IMG_0795.jpg\n",
      "../data/test/mouth/Normal/IMG_0796.jpg\n",
      "../data/test/mouth/Normal/Photo on 2023-01-31 at 12.46 PM #3.jpg\n",
      "../data/test/mouth/Normal/Photo on 2023-01-31 at 12.46 PM #4.jpg\n",
      "../data/test/mouth/Normal/Photo on 2023-01-31 at 4.54 PM.jpg\n",
      "../data/test/mouth/Normal/Photo on 2023-02-01 at 2.01 PM.jpg\n",
      "../data/test/mouth/Normal/WIN_20221126_16_12_36_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221126_16_12_43_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221128_19_53_14_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221128_19_53_22_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221130_12_27_58_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221130_12_28_10_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221130_12_28_12_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20221130_12_28_14_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20230204_13_38_27_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20230204_13_38_39_Pro.jpg\n",
      "../data/test/mouth/Normal/WIN_20230204_13_39_00_Pro.jpg\n",
      "../data/test/mouth/Yawning/327781720_1287182322180121_2380712887574834957_n.jpg\n",
      "../data/test/mouth/Yawning/328159127_5704289616364313_5636526142790564247_n.jpg\n",
      "../data/test/mouth/Yawning/328657782_1384994308922613_901228431867776909_n.jpg\n",
      "../data/test/mouth/Yawning/IMG-4718.jpg\n",
      "../data/test/mouth/Yawning/IMG-4719.jpg\n",
      "../data/test/mouth/Yawning/IMG-4720.jpg\n",
      "../data/test/mouth/Yawning/IMG-4721.jpg\n",
      "../data/test/mouth/Yawning/IMG-4722.jpg\n",
      "../data/test/mouth/Yawning/IMG-4723 (1).jpg\n",
      "../data/test/mouth/Yawning/IMG-4724.jpg\n",
      "../data/test/mouth/Yawning/IMG_0162.jpg\n",
      "../data/test/mouth/Yawning/IMG_0165.jpg\n",
      "../data/test/mouth/Yawning/IMG_0167(1).jpg\n",
      "../data/test/mouth/Yawning/IMG_0168.jpg\n",
      "../data/test/mouth/Yawning/IMG_0800.jpg\n",
      "../data/test/mouth/Yawning/IMG_0801.jpg\n",
      "../data/test/mouth/Yawning/IMG_0802.jpg\n",
      "../data/test/mouth/Yawning/Photo on 2023-01-31 at 12.46 PM #2.jpg\n",
      "../data/test/mouth/Yawning/Photo on 2023-01-31 at 12.48 PM.jpg\n",
      "../data/test/mouth/Yawning/Photo on 2023-01-31 at 4.54 PM #2.jpg\n",
      "../data/test/mouth/Yawning/Photo on 2023-02-01 at 2.01 PM #3.jpg\n",
      "../data/test/mouth/Yawning/WIN_20221130_12_28_05_Pro.jpg\n",
      "../data/test/mouth/Yawning/WIN_20221130_12_28_17_Pro.jpg\n",
      "../data/test/mouth/Yawning/WIN_20221130_12_35_32_Pro.jpg\n",
      "../data/test/mouth/Yawning/WIN_20230204_13_39_26_Pro.jpg\n",
      "../data/test/mouth/Yawning/WIN_20230204_13_39_32_Pro.jpg\n",
      "../data/test/mouth/Yawning/WIN_20230204_13_43_14_Pro.jpg\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "root = \"../data/test/mouth/\"\n",
    "total = 0\n",
    "correct = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for folder in os.listdir(root):\n",
    "    for im in os.listdir(root + folder):\n",
    "        path = root + folder + \"/\" + im\n",
    "        mouthImage = mouth_cropper(path)\n",
    "        eyes = eye_cropper(path)\n",
    "        drowsy = False\n",
    "\n",
    "        if mouthImage:\n",
    "            mouthImage = image.img_to_array(mouthImage)\n",
    "            mouthImage = mouthImage/255.0\n",
    "            mouthImage = np.expand_dims(mouthImage, axis=0)\n",
    "            \n",
    "            images = np.vstack([mouthImage])\n",
    "            classes = mouthModel.predict(images)\n",
    "\n",
    "            if classes[0]>0.5:\n",
    "                drowsy = True\n",
    "\n",
    "        if eyes:\n",
    "            left, right = eyes[0], eyes[1]\n",
    "            left, right = image.img_to_array(left), image.img_to_array(right)\n",
    "            left, right = left/255.0, right/255.0\n",
    "            left, right = np.expand_dims(left, axis=0), np.expand_dims(right, axis=0)\n",
    "            left, right = np.vstack([left]), np.vstack([right])\n",
    "            left, right = eyesModel.predict(left), eyesModel.predict(right)\n",
    "            if left[0] > 0.5 and right[0] > 0.5:\n",
    "                drowsy = True\n",
    "\n",
    "        if drowsy and folder == \"Yawning\":\n",
    "            correct += 1\n",
    "            TP += 1\n",
    "        elif not drowsy and folder == \"Normal\":\n",
    "            correct += 1\n",
    "        elif drowsy and folder == \"Normal\":\n",
    "            FP += 1\n",
    "        elif not drowsy and folder == \"Yawning\":\n",
    "            FN += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4838709677419355\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
