{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN-RNN using VGG16. RNN is created without GRU and trainned with 100 frames from each video.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import glob,os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_W = 224\n",
    "IMG_H = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_SEQ_LENGTH = 100\n",
    "NUM_FEATURES = 2048\n",
    "\n",
    "df1 = pd.read_csv(\"../Data/mirror-data2.csv\")\n",
    "df1 = df1[df1.Action != (\"Talking\" or \"talking\")]\n",
    "df1.head()\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(frames,  resize=(IMG_H, IMG_W)):\n",
    "    \n",
    "    frames = []\n",
    "    for frame in frames:\n",
    "\n",
    "        frame = crop_center_square(frame)\n",
    "        frame = cv2.resize(frame, resize)\n",
    "        frame = frame[:, :, [2, 1, 0]]\n",
    "        frames.append(frame)\n",
    "\n",
    "        \n",
    "    \n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_VGG16_model():\n",
    "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "  print(base_model.summary())\n",
    "  return base_model\n",
    "\n",
    "\n",
    "feature_extractor = load_VGG16_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal', 'Talking&Yawning', 'Yawning', 'talking']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(df1['Action'])\n",
    ")\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "\n",
    "i = 0\n",
    "dfTrain = pd.DataFrame()\n",
    "dfTest = pd.DataFrame()\n",
    "\n",
    "while i<len(df1):\n",
    "    if i%5==0:\n",
    "        dfTest = dfTest.append(df1.iloc[[i]])\n",
    "    else :\n",
    "        dfTrain = dfTrain.append(df1.iloc[[i]])\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/VideoFrames/1-FemaleNoGlasses-Yawning.avi/1-FemaleNoGlasses-Yawning.avi_150.jpg\n",
      "../Data/VideoFrames/2-FemaleNoGlasses-Normal.avi/2-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/2-FemaleNoGlasses-Yawning.avi/2-FemaleNoGlasses-Yawning.avi_475.jpg\n",
      "../Data/VideoFrames/3-FemaleGlasses-Normal.avi/3-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/4-FemaleGlasses-Normal.avi/4-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/4-FemaleGlasses-Yawning.avi/4-FemaleGlasses-Yawning.avi_110.jpg\n",
      "../Data/VideoFrames/5-FemaleGlasses-Normal.avi/5-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/5-FemaleGlasses-Yawning.avi/5-FemaleGlasses-Yawning.avi_240.jpg\n",
      "../Data/VideoFrames/6-FemaleNoGlasses-Yawning.avi/6-FemaleNoGlasses-Yawning.avi_220.jpg\n",
      "../Data/VideoFrames/7-FemaleGlasses-Normal.avi/7-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/7-FemaleGlasses-Yawning.avi/7-FemaleGlasses-Yawning.avi_185.jpg\n",
      "../Data/VideoFrames/8-FemaleGlasses-Normal.avi/8-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/9-FemaleNoGlasses-Normal.avi/9-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/9-FemaleNoGlasses-Yawning.avi/9-FemaleNoGlasses-Yawning.avi_145.jpg\n",
      "../Data/VideoFrames/10-FemaleNoGlasses-Normal.avi/10-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/10-FemaleNoGlasses-Yawning.avi/10-FemaleNoGlasses-Yawning.avi_120.jpg\n",
      "../Data/VideoFrames/11-FemaleNoGlasses-Yawning.avi/11-FemaleNoGlasses-Yawning.avi_260.jpg\n",
      "../Data/VideoFrames/12-FemaleNoGlasses-Normal.avi/12-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/12-FemaleNoGlasses-Yawning.avi/12-FemaleNoGlasses-Yawning.avi_645.jpg\n",
      "../Data/VideoFrames/13-FemaleNoGlasses-Normal.avi/13-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/14-FemaleNoGlasses-Normal.avi/14-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/14-FemaleNoGlasses-Yawning.avi/14-FemaleNoGlasses-Yawning.avi_330.jpg\n",
      "../Data/VideoFrames/15-FemaleGlasses-Normal.avi/15-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/15-FemaleGlasses-Yawning.avi/15-FemaleGlasses-Yawning.avi_240.jpg\n",
      "../Data/VideoFrames/15-FemaleSunGlasses-Yawning.avi/15-FemaleSunGlasses-Yawning.avi_240.jpg\n",
      "../Data/VideoFrames/16-FemaleGlasses-Normal.avi/16-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/16-FemaleGlasses-Yawning.avi/16-FemaleGlasses-Yawning.avi_160.jpg\n",
      "../Data/VideoFrames/17-FemaleNoGlasses-Normal.avi/17-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/17-FemaleSunGlasses-Normal.avi/17-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/17-FemaleSunGlasses-Yawning.avi/17-FemaleSunGlasses-Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/18-FemaleNoGlasses-Normal.avi/18-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/18-FemaleNoGlasses-Yawning.avi/18-FemaleNoGlasses-Yawning.avi_170.jpg\n",
      "../Data/VideoFrames/18-FemaleSunGlasses-Yawning.avi/18-FemaleSunGlasses-Yawning.avi_280.jpg\n",
      "../Data/VideoFrames/19-FemaleNoGlasses-Normal.avi/19-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/19-FemaleNoGlasses-Yawning.avi/19-FemaleNoGlasses-Yawning.avi_240.jpg\n",
      "../Data/VideoFrames/20-FemaleNoGlasses-Normal.avi/20-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/21-FemaleNoGlasses-Normal.avi/21-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/21-FemaleNoGlasses-Yawning.avi/21-FemaleNoGlasses-Yawning.avi_200.jpg\n",
      "../Data/VideoFrames/22-FemaleNoGlasses-Normal.avi/22-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/22-FemaleNoGlasses-Yawning.avi/22-FemaleNoGlasses-Yawning.avi_300.jpg\n",
      "../Data/VideoFrames/22-FemaleSunGlasses-Yawning.avi/22-FemaleSunGlasses-Yawning.avi_210.jpg\n",
      "../Data/VideoFrames/23-FemaleNoGlasses-Normal.avi/23-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/23-FemaleNoGlasses-Talking&Yawning.avi/23-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/23-FemaleNoGlasses-Yawning.avi/23-FemaleNoGlasses-Yawning.avi_244.jpg\n",
      "../Data/VideoFrames/24-FemaleNoGlasses-Yawning.avi/24-FemaleNoGlasses-Yawning.avi_270.jpg\n",
      "../Data/VideoFrames/25-FemaleNoGlasses-Normal.avi/25-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/25-FemaleNoGlasses-Yawning.avi/25-FemaleNoGlasses-Yawning.avi_140.jpg\n",
      "../Data/VideoFrames/25-FemaleSunGlasses-Normal.avi/25-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/26-FemaleGlasses-Normal.avi/26-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/26-FemaleGlasses-Yawning.avi/26-FemaleGlasses-Yawning.avi_240.jpg\n",
      "../Data/VideoFrames/26-FemaleSunGlasses-Normal.avi/26-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/26-FemaleSunGlasses-Yawning.avi/26-FemaleSunGlasses-Yawning.avi_125.jpg\n",
      "../Data/VideoFrames/27-FemaleNoGlasses-Talking&Yawning.avi/27-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/27-FemaleSunGlasses-Normal.avi/27-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/27-FemaleSunGlasses-Yawning.avi/27-FemaleSunGlasses-Yawning.avi_260.jpg\n",
      "../Data/VideoFrames/28-FemaleNoGlasses-Normal.avi/28-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/29-FemaleNoGlasses-Normal.avi/29-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/29-FemaleNoGlasses-Yawning.avi/29-FemaleNoGlasses-Yawning.avi_250.jpg\n",
      "../Data/VideoFrames/30-FemaleNoGlasses-Normal.avi/30-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/30-FemaleNoGlasses-Yawning.avi/30-FemaleNoGlasses-Yawning.avi_450.jpg\n",
      "../Data/VideoFrames/31-FemaleGlasses-Yawning.avi/31-FemaleGlasses-Yawning.avi_290.jpg\n",
      "../Data/VideoFrames/31-FemaleNoGlasses-Normal.avi/31-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/31-FemaleNoGlasses-Yawning.avi/31-FemaleNoGlasses-Yawning.avi_278.jpg\n",
      "../Data/VideoFrames/32-FemaleSunGlasses-Normal.avi/32-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/33-FemaleNoGlasses-Normal.avi/33-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/33-FemaleNoGlasses-Yawning.avi/33-FemaleNoGlasses-Yawning.avi_345.jpg\n",
      "../Data/VideoFrames/34-FemaleNoGlasses-Normal.avi/34-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/34-FemaleNoGlasses-Talking&Yawning.avi/34-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/35-FemaleNoGlasses-Normal.avi/35-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/35-FemaleNoGlasses-Talking&Yawning.avi/35-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/35-FemaleNoGlasses-Yawning.avi/35-FemaleNoGlasses-Yawning.avi_138.jpg\n",
      "../Data/VideoFrames/36-FemaleNoGlasses-Normal.avi/36-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/36-FemaleNoGlasses-Yawning.avi/36-FemaleNoGlasses-Yawning.avi_295.jpg\n",
      "../Data/VideoFrames/37-FemaleNoGlasses-Normal.avi/37-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/37-FemaleNoGlasses-Talking&Yawning.avi/37-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/37-FemaleNoGlasses-Yawning.avi/37-FemaleNoGlasses-Yawning.avi_175.jpg\n",
      "../Data/VideoFrames/38-FemaleNoGlasses-Yawning.avi/38-FemaleNoGlasses-Yawning.avi_260.jpg\n",
      "../Data/VideoFrames/39-FemaleNoGlasses-Normal.avi/39-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/39-FemaleNoGlasses-Talking&Yawning.avi/39-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/39-FemaleNoGlasses-Yawning.avi/39-FemaleNoGlasses-Yawning.avi_220.jpg\n",
      "../Data/VideoFrames/40-FemaleNoGlasses-Yawning.avi/40-FemaleNoGlasses-Yawning.avi_386.jpg\n",
      "../Data/VideoFrames/41-FemaleGlasses-Normal.avi/41-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/41-FemaleGlasses-Yawning.avi/41-FemaleGlasses-Yawning.avi_290.jpg\n",
      "../Data/VideoFrames/42-FemaleSunGlasses-Normal.avi/42-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/43-FemaleNoGlasses-Normal.avi/43-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/43-FemaleNoGlasses-Yawning.avi/43-FemaleNoGlasses-Yawning.avi_290.jpg\n",
      "../Data/VideoFrames/1-MaleNoGlasses-Yawning.avi/1-MaleNoGlasses-Yawning.avi_270.jpg\n",
      "../Data/VideoFrames/1-MaleSunGlasses-Normal.avi/1-MaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/2-MaleGlasses-Normal.avi/2-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/2-MaleGlasses-Yawning.avi/2-MaleGlasses-Yawning.avi_230.jpg\n",
      "../Data/VideoFrames/3-MaleGlasses-Normal.avi/3-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/3-MaleGlasses-Yawning.avi/3-MaleGlasses-Yawning.avi_175.jpg\n",
      "../Data/VideoFrames/3-MaleNoGlasses-Yawning.avi/3-MaleNoGlasses-Yawning.avi_190.jpg\n",
      "../Data/VideoFrames/4-MaleNoGlasses-Normal.avi/4-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/4-MaleNoGlasses-Yawning.avi/4-MaleNoGlasses-Yawning.avi_155.jpg\n",
      "../Data/VideoFrames/5-MaleNoGlasses-Normal.avi/5-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/6-MaleNoGlasses-Normal.avi/6-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/6-MaleNoGlasses-Yawning.avi/6-MaleNoGlasses-Yawning.avi_127.jpg\n",
      "../Data/VideoFrames/7-MaleGlasses-Normal.avi/7-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/7-MaleGlasses-Yawning.avi/7-MaleGlasses-Yawning.avi_190.jpg\n",
      "../Data/VideoFrames/8-MaleGlassesBeard-Yawning.avi/8-MaleGlassesBeard-Yawning.avi_175.jpg\n",
      "../Data/VideoFrames/9-MaleNoGlasses-Normal.avi/9-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/9-MaleNoGlasses-Yawning.avi/9-MaleNoGlasses-Yawning.avi_180.jpg\n",
      "../Data/VideoFrames/10-MaleNoGlasses-Normal.avi/10-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/11-MaleGlasses-Normal.avi/11-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/11-MaleGlasses-Yawning.avi/11-MaleGlasses-Yawning.avi_420.jpg\n",
      "../Data/VideoFrames/12-MaleGlasses-Normal.avi/12-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/12-MaleGlasses-Yawning.avi/12-MaleGlasses-Yawning.avi_290.jpg\n",
      "../Data/VideoFrames/13-MaleGlasses-Yawning.avi/13-MaleGlasses-Yawning.avi_160.jpg\n",
      "../Data/VideoFrames/14-MaleGlasses-Normal.avi/14-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/15-MaleNoGlasses-Normal.avi/15-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/15-MaleNoGlasses-Talking.avi/15-MaleNoGlasses-Talking.avi_100.jpg\n",
      "../Data/VideoFrames/16-MaleNoGlasses-Normal.avi/16-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/17-MaleNoGlasses-Normal.avi/17-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/17-MaleNoGlasses-Yawning.avi/17-MaleNoGlasses-Yawning.avi_260.jpg\n",
      "../Data/VideoFrames/18-MaleNoGlasses-Normal.avi/18-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/19-MaleGlassesmoustache-Normal.avi/19-MaleGlassesmoustache-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/19-MaleGlassesmoustache-Yawning.avi/19-MaleGlassesmoustache-Yawning.avi_167.jpg\n",
      "../Data/VideoFrames/20-MaleGlasses-Normal.avi/20-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/20-MaleGlasses-Talking.avi/20-MaleGlasses-Talking.avi_100.jpg\n",
      "../Data/VideoFrames/21-MaleGlasses-Yawning.avi/21-MaleGlasses-Yawning.avi_246.jpg\n",
      "../Data/VideoFrames/22-MaleGlassesmoustache-Normal.avi/22-MaleGlassesmoustache-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/22-MaleGlassesmoustache-Yawning.avi/22-MaleGlassesmoustache-Yawning.avi_182.jpg\n",
      "../Data/VideoFrames/23-MaleGlassesBeard-Normal.avi/23-MaleGlassesBeard-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/23-MaleGlassesBeard-Yawning.avi/23-MaleGlassesBeard-Yawning.avi_270.jpg\n",
      "../Data/VideoFrames/23-MaleNoGlasses-Normal.avi/23-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/23-MaleNoGlasses-Yawning.avi/23-MaleNoGlasses-Yawning.avi_242.jpg\n",
      "../Data/VideoFrames/24-MaleGlasses-Normal.avi/24-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/25-MaleGlasses-Normal.avi/25-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/25-MaleGlasses-Yawning.avi/25-MaleGlasses-Yawning.avi_290.jpg\n",
      "../Data/VideoFrames/25-MaleSunGlasses-Normal.avi/25-MaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/25-MaleSunGlasses-Yawning.avi/25-MaleSunGlasses-Yawning.avi_170.jpg\n",
      "../Data/VideoFrames/26-MaleNoGlasses-Yawning.avi/26-MaleNoGlasses-Yawning.avi_220.jpg\n",
      "../Data/VideoFrames/27-MaleGlasses-Normal.avi/27-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/27-MaleGlasses-Yawning.avi/27-MaleGlasses-Yawning.avi_115.jpg\n",
      "../Data/VideoFrames/27-MaleNoGlasses-Normal.avi/27-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/28-MaleGlasses-Normal.avi/28-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/28-MaleGlasses-Yawning.avi/28-MaleGlasses-Yawning.avi_265.jpg\n",
      "../Data/VideoFrames/28-MaleNoGlasses-Normal.avi/28-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/28-MaleNoGlasses-Yawning.avi/28-MaleNoGlasses-Yawning.avi_258.jpg\n",
      "../Data/VideoFrames/29-MaleNoGlasses-Yawning.avi/29-MaleNoGlasses-Yawning.avi_245.jpg\n",
      "../Data/VideoFrames/30-MaleGlasses-Normal.avi/30-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/30-MaleGlasses-Talking&Yawning.avi/30-MaleGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/30-MaleGlasses-Yawning.avi/30-MaleGlasses-Yawning.avi_228.jpg\n",
      "../Data/VideoFrames/31-MaleGlasses-Yawning.avi/31-MaleGlasses-Yawning.avi_115.jpg\n",
      "../Data/VideoFrames/32-MaleGlasses-Normal.avi/32-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/32-MaleGlasses-Talking&Yawning.avi/32-MaleGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/32-MaleGlasses-Yawning.avi/32-MaleGlasses-Yawning.avi_310.jpg\n",
      "../Data/VideoFrames/33-MaleGlasses-Talking&Yawning.avi/33-MaleGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/33-MaleGlasses-Yawning.avi/33-MaleGlasses-Yawning.avi_260.jpg\n",
      "../Data/VideoFrames/34-MaleNoGlasses-Normal.avi/34-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/34-MaleNoGlasses-Yawning.avi/34-MaleNoGlasses-Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/35-MaleNoGlasses-Yawning.avi/35-MaleNoGlasses-Yawning.avi_275.jpg\n",
      "../Data/VideoFrames/36-MaleNoGlasses-Normal.avi/36-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/36-MaleNoGlasses-Yawning.avi/36-MaleNoGlasses-Yawning.avi_240.jpg\n",
      "../Data/VideoFrames/36-MaleSunGlasses-Normal.avi/36-MaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/37-MaleNoGlasses-Normal.avi/37-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/37-MaleNoGlasses-Yawning.avi/37-MaleNoGlasses-Yawning.avi_270.jpg\n",
      "../Data/VideoFrames/38-MaleNoGlasses-Normal.avi/38-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/38-MaleNoGlasses-Yawning.avi/38-MaleNoGlasses-Yawning.avi_274.jpg\n",
      "../Data/VideoFrames/38-MaleSunGlasses-Yawning.avi/38-MaleSunGlasses-Yawning.avi_208.jpg\n",
      "../Data/VideoFrames/39-MaleGlasses-Normal.avi/39-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/39-MaleGlasses-Yawning.avi/39-MaleGlasses-Yawning.avi_470.jpg\n",
      "../Data/VideoFrames/40-MaleNoGlasses-Normal.avi/40-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/41-MaleNoGlasses-Normal.avi/41-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/41-MaleNoGlasses-Yawning.avi/41-MaleNoGlasses-Yawning.avi_245.jpg\n",
      "../Data/VideoFrames/42-MaleNoGlasses-Normal.avi/42-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/42-MaleNoGlasses-Yawning.avi/42-MaleNoGlasses-Yawning.avi_320.jpg\n",
      "../Data/VideoFrames/43-MaleNoGlasses-Yawning.avi/43-MaleNoGlasses-Yawning.avi_276.jpg\n",
      "../Data/VideoFrames/44-MaleNoGlasses-Normal.avi/44-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/44-MaleNoGlasses-Yawning.avi/44-MaleNoGlasses-Yawning.avi_170.jpg\n",
      "../Data/VideoFrames/45-MaleNoGlasses-Normal.avi/45-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/46-MaleGlasses-Normal.avi/46-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/46-MaleGlasses-Yawning.avi/46-MaleGlasses-Yawning.avi_369.jpg\n",
      "../Data/VideoFrames/47-MaleNoGlasses-Normal.avi/47-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/47-MaleNoGlasses-Yawning.avi/47-MaleNoGlasses-Yawning.avi_370.jpg\n",
      "../Data/VideoFrames/1-FemaleNoGlasses-Normal.avi/1-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/3-FemaleGlasses-Yawning.avi/3-FemaleGlasses-Yawning.avi_150.jpg\n",
      "../Data/VideoFrames/6-FemaleNoGlasses-Normal.avi/6-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/8-FemaleGlasses-Yawning.avi/8-FemaleGlasses-Yawning.avi_190.jpg\n",
      "../Data/VideoFrames/11-FemaleNoGlasses-Normal.avi/11-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/13-FemaleNoGlasses-Yawning.avi/13-FemaleNoGlasses-Yawning.avi_330.jpg\n",
      "../Data/VideoFrames/15-FemaleSunGlasses-Normal.avi/15-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/17-FemaleNoGlasses-Yawning.avi/17-FemaleNoGlasses-Yawning.avi_135.jpg\n",
      "../Data/VideoFrames/18-FemaleSunGlasses-Normal.avi/18-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/20-FemaleNoGlasses-Yawning.avi/20-FemaleNoGlasses-Yawning.avi_285.jpg\n",
      "../Data/VideoFrames/22-FemaleSunGlasses-Normal.avi/22-FemaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/24-FemaleNoGlasses-Normal.avi/24-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/25-FemaleSunGlasses-Yawning.avi/25-FemaleSunGlasses-Yawning.avi_145.jpg\n",
      "../Data/VideoFrames/27-FemaleNoGlasses-Normal.avi/27-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/28-FemaleNoGlasses-Yawning.avi/28-FemaleNoGlasses-Yawning.avi_200.jpg\n",
      "../Data/VideoFrames/31-FemaleGlasses-Normal.avi/31-FemaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/32-FemaleSunGlasses-Yawning.avi/32-FemaleSunGlasses-Yawning.avi_600.jpg\n",
      "../Data/VideoFrames/34-FemaleNoGlasses-Yawning.avi/34-FemaleNoGlasses-Yawning.avi_230.jpg\n",
      "../Data/VideoFrames/36-FemaleNoGlasses-Talking&Yawning.avi/36-FemaleNoGlasses-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/38-FemaleNoGlasses-Normal.avi/38-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/40-FemaleNoGlasses-Normal.avi/40-FemaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/42-FemaleSunGlasses-Yawning.avi/42-FemaleSunGlasses-Yawning.avi_340.jpg\n",
      "../Data/VideoFrames/1-MaleSunGlasses-Yawning.avi/1-MaleSunGlasses-Yawning.avi_225.jpg\n",
      "../Data/VideoFrames/3-MaleNoGlasses-Normal.avi/3-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/5-MaleNoGlasses-Yawning.avi/5-MaleNoGlasses-Yawning.avi_215.jpg\n",
      "../Data/VideoFrames/8-MaleGlassesBeard-Normal.avi/8-MaleGlassesBeard-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/10-MaleNoGlasses-Yawning.avi/10-MaleNoGlasses-Yawning.avi_105.jpg\n",
      "../Data/VideoFrames/13-MaleGlasses-Normal.avi/13-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/15-MaleNoGlasses-Yawning.avi/15-MaleNoGlasses-Yawning.avi_170.jpg\n",
      "../Data/VideoFrames/18-MaleNoGlasses-Yawning.avi/18-MaleNoGlasses-Yawning.avi_255.jpg\n",
      "../Data/VideoFrames/21-MaleGlasses-Normal.avi/21-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/23-MaleGlassesBeard-Talking&Yawning.avi/23-MaleGlassesBeard-Talking&Yawning.avi_100.jpg\n",
      "../Data/VideoFrames/24-MaleGlasses-Yawning.avi/24-MaleGlasses-Yawning.avi_340.jpg\n",
      "../Data/VideoFrames/26-MaleNoGlasses-Normal.avi/26-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/27-MaleNoGlasses-Yawning.avi/27-MaleNoGlasses-Yawning.avi_260.jpg\n",
      "../Data/VideoFrames/29-MaleNoGlasses-Normal.avi/29-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/31-MaleGlasses-Normal.avi/31-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/33-MaleGlasses-Normal.avi/33-MaleGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/35-MaleNoGlasses-Normal.avi/35-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/36-MaleSunGlasses-Yawning.avi/36-MaleSunGlasses-Yawning.avi_280.jpg\n",
      "../Data/VideoFrames/38-MaleSunGlasses-Normal.avi/38-MaleSunGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/40-MaleNoGlasses-Yawning.avi/40-MaleNoGlasses-Yawning.avi_295.jpg\n",
      "../Data/VideoFrames/43-MaleNoGlasses-Normal.avi/43-MaleNoGlasses-Normal.avi_100.jpg\n",
      "../Data/VideoFrames/45-MaleNoGlasses-Yawning.avi/45-MaleNoGlasses-Yawning.avi_255.jpg\n",
      "Frame features in train set: (176, 100, 2048)\n",
      "Frame masks in train set: (176, 100)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video-name\"].values.tolist()\n",
    "    start_nums = df[\"yawn-start\"].values.tolist()\n",
    "    # print(video_paths)\n",
    "    labels = df[\"Action\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        videoName = path\n",
    "        number = start_nums[idx]\n",
    "        frames = []\n",
    "\n",
    "        while(len(frames)<=MAX_SEQ_LENGTH):\n",
    "            path = \"../Data/VideoFrames/\"+videoName+\"/\"+videoName+\"_\"+f\"{number:03}\"+\".jpg\"\n",
    "            frames.append(image.load_img(path, target_size=(224, 224, 3)))\n",
    "            number+=1\n",
    "        print(path)\n",
    "\n",
    "\n",
    "        frames = load_video(frames)\n",
    "        frames = frames[None, ...]\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "        # Extract features from the frames of the current video.\n",
    "        \n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(dfTrain, \"../Data/Mirror\")\n",
    "test_data, test_labels = prepare_all_videos(dfTest, \"../Data/Mirror\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data,train_labels,validation_data,validation_labels):\n",
    "  ''' used fully connected layers, SGD optimizer and \n",
    "      checkpoint to store the best weights'''\n",
    "  frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "  mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(256,dropout=0.2,input_shape=(MAX_SEQ_LENGTH, NUM_FEATURES)))\n",
    "  model.add(Dense(1024, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(5, activation='softmax'))\n",
    "  sgd = SGD(lr=0.00005, decay = 1e-6, momentum=0.9, nesterov=True)\n",
    "  model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "  #model.load_weights('video_1_LSTM_1_512.h5')\n",
    "  #callbacks = [ EarlyStopping(monitor='val_loss', patience=10, verbose=0), ModelCheckpoint('video_1_LSTM_1_1024.h5', monitor='val_loss', save_best_only=True, verbose=0) ]\n",
    "  nb_epoch = 500\n",
    "  model.fit(train_data,train_labels,validation_data=(validation_data,validation_labels),shuffle=True,verbose=1, epochs = 15)\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnich\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 1.6094 - accuracy: 0.4034WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x0000020D066AC4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6/6 [==============================] - 6s 773ms/step - loss: 1.6094 - accuracy: 0.4034 - val_loss: 1.6092 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "6/6 [==============================] - 4s 700ms/step - loss: 1.6090 - accuracy: 0.4602 - val_loss: 1.6087 - val_accuracy: 0.5000\n",
      "Epoch 3/15\n",
      "6/6 [==============================] - 4s 665ms/step - loss: 1.6085 - accuracy: 0.4716 - val_loss: 1.6081 - val_accuracy: 0.5000\n",
      "Epoch 4/15\n",
      "6/6 [==============================] - 4s 707ms/step - loss: 1.6079 - accuracy: 0.4716 - val_loss: 1.6074 - val_accuracy: 0.5000\n",
      "Epoch 5/15\n",
      "6/6 [==============================] - 5s 820ms/step - loss: 1.6072 - accuracy: 0.4716 - val_loss: 1.6067 - val_accuracy: 0.5000\n",
      "Epoch 6/15\n",
      "6/6 [==============================] - 5s 802ms/step - loss: 1.6065 - accuracy: 0.4716 - val_loss: 1.6060 - val_accuracy: 0.5000\n",
      "Epoch 7/15\n",
      "6/6 [==============================] - 5s 759ms/step - loss: 1.6059 - accuracy: 0.4716 - val_loss: 1.6052 - val_accuracy: 0.5000\n",
      "Epoch 8/15\n",
      "6/6 [==============================] - 4s 746ms/step - loss: 1.6051 - accuracy: 0.4716 - val_loss: 1.6045 - val_accuracy: 0.5000\n",
      "Epoch 9/15\n",
      "6/6 [==============================] - 5s 775ms/step - loss: 1.6044 - accuracy: 0.4716 - val_loss: 1.6038 - val_accuracy: 0.5000\n",
      "Epoch 10/15\n",
      "6/6 [==============================] - 5s 780ms/step - loss: 1.6037 - accuracy: 0.4716 - val_loss: 1.6030 - val_accuracy: 0.5000\n",
      "Epoch 11/15\n",
      "6/6 [==============================] - 4s 751ms/step - loss: 1.6030 - accuracy: 0.4716 - val_loss: 1.6023 - val_accuracy: 0.5000\n",
      "Epoch 12/15\n",
      "6/6 [==============================] - 5s 933ms/step - loss: 1.6023 - accuracy: 0.4716 - val_loss: 1.6016 - val_accuracy: 0.5000\n",
      "Epoch 13/15\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6016 - accuracy: 0.4716 - val_loss: 1.6008 - val_accuracy: 0.5000\n",
      "Epoch 14/15\n",
      "6/6 [==============================] - 5s 825ms/step - loss: 1.6009 - accuracy: 0.4716 - val_loss: 1.6001 - val_accuracy: 0.5000\n",
      "Epoch 15/15\n",
      "6/6 [==============================] - 5s 756ms/step - loss: 1.6002 - accuracy: 0.4716 - val_loss: 1.5994 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x20d06683d30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_data[0], train_labels, test_data[0], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_whole_videos(train_data,train_labels,validation_data,validation_labels):\n",
    "  parent = os.listdir(\"/Users/.../video/test\")\n",
    "  #.....................................Testing on whole videos.................................................................\n",
    "  x = []\n",
    "  y = []\n",
    "  count = 0\n",
    "  output = 0\n",
    "  count_video = 0\n",
    "  correct_video = 0\n",
    "  total_video = 0\n",
    "  base_model = load_VGG16_model()\n",
    "  model = train_model(train_data,train_labels,validation_data,validation_labels)\n",
    "  for video_class in parent[1:]:\n",
    "      print video_class\n",
    "      child = os.listdir(\"/Users/.../video/test\" + \"/\" + video_class)\n",
    "      for class_i in child[1:]:\n",
    "          sub_child = os.listdir(\"/Users/.../video/test\" + \"/\" + video_class + \"/\" + class_i)\n",
    "          for image_fol in sub_child[1:]:\n",
    "              if (video_class ==  'class_4' ):\n",
    "                  if(count%4 == 0):\n",
    "                      image = imread(\"/Users/.../video/test\" + \"/\" + video_class + \"/\" + class_i + \"/\" + image_fol)\n",
    "                      image = imresize(image , (224,224))\n",
    "\n",
    "                      x.append(image)\n",
    "                      y.append(output)\n",
    "                      #cv2.imwrite('/Users/.../video/validate/' + video_class + '/' + str(count) + '_' + image_fol,image)\n",
    "                  count+=1\n",
    "\n",
    "              else:\n",
    "                  if(count%4 == 0):\n",
    "                      image = imread(\"/Users/.../video/test\" + \"/\" + video_class + \"/\" + class_i + \"/\" + image_fol)\n",
    "                      image = imresize(image , (224,224))\n",
    "                      x.append(image)\n",
    "                      y.append(output)\n",
    "                      #cv2.imwrite('/Users/.../video/validate/' + video_class + '/' + str(count) + '_' + image_fol,image)\n",
    "                  count+=1\n",
    "          #correct_video+=1\n",
    "          x = np.array(x)\n",
    "          y = np.array(y)\n",
    "          x_features = base_model.predict(x)\n",
    "          #np.save(open('feat_' + 'class_' + str(output) + '_' + str(count_video) +'_'  + '.npy','w'),x)\n",
    "\n",
    "          correct = 0\n",
    "          \n",
    "          answer = model.predict(x_features)\n",
    "          for i in range(len(answer)):\n",
    "              if(y[i] == np.argmax(answer[i])):\n",
    "                  correct+=1\n",
    "          print correct,\"correct\",len(answer)\n",
    "          total_video+=1\n",
    "          if(correct>= len(answer)/2):\n",
    "              correct_video+=1\n",
    "          x = []\n",
    "          y = []\n",
    "          count_video+=1\n",
    "      output+=1\n",
    "\n",
    "  print(\"correct_video\",correct_video,\"total_video\",total_video)\n",
    "  print(\"The accuracy for video classification of \",total_video, \" videos is \", (correct_video/total_video))\n",
    "  \n",
    "\n",
    "base_model = load_VGG16_model()\n",
    "train_data,train_labels,validation_data,validation_labels = extract_features_and_store(train_generator,validation_generator,base_model)\n",
    "train_model(train_data,train_labels,validation_data,validation_labels)\n",
    "test_on_whole_videos(train_data,train_labels,validation_data,validation_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3deb5058a37522a2e4ac59617ed5a8c2cf9a3176becbc0158883759547460f28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
