{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/archive/cross-val/mouth/mouthLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped mouth\n",
    "train_data = pd.read_csv('../data/archive/cross-val/mouth-cropped/mouthLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg  = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"base_yawning_model.h5\")\n",
    "#model = keras.models.load_model(\"yawning_model.h5\")\n",
    "#model = keras.models.load_model(\"mobilenet_yawning_model.h5\")\n",
    "#model = keras.models.load_model(\"base_cropped_yawning_model.h5\")\n",
    "#model = keras.models.load_model(\"inception_cropped_yawning_model.h5\")\n",
    "model = keras.models.load_model(\"mobileV2_cropped_yawning_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 validated image filenames belonging to 2 classes.\n",
      "8/8 [==============================] - 2s 44ms/step - loss: 1.2218 - accuracy: 0.9022\n",
      "Found 225 validated image filenames belonging to 2 classes.\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1033 - accuracy: 0.8489\n",
      "Found 224 validated image filenames belonging to 2 classes.\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.8619 - accuracy: 0.8616\n",
      "Found 224 validated image filenames belonging to 2 classes.\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2959 - accuracy: 0.8884\n",
      "Found 224 validated image filenames belonging to 2 classes.\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.9399 - accuracy: 0.8482\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "for train_index, val_index in skf.split(np.zeros(len(Y)),Y):\n",
    "\tvalidation_data = train_data.iloc[val_index]\n",
    "\t\n",
    "\t# cropped mouth is (80, 80) else (224, 224) \n",
    "\tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = '../data/archive/', target_size=(80, 80),\n",
    "\t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t\tclass_mode = \"binary\", shuffle = True)\n",
    "\t\n",
    "\tresults = model.evaluate(valid_data_generator)\n",
    "\tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "\tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "\tVALIDATION_LOSS.append(results['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9679285764694214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # base cropped yawning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964325547218322"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # inception cropped yawning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869865071773529"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # mobile cropped yawning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356520533561707"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # base yawning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958501338958741"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # inceptionresnetv2 yawning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927481210231781"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # mobilenet_yawning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4298e6fd6da2fe1fbdbe55781d0a378dd9562c1f5795e48e37a7037879961298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
