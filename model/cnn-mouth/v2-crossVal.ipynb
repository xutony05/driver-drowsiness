{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/archive/cross-val/mouth/mouthLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg  = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    base_model = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1158 validated image filenames belonging to 2 classes.\n",
      "Found 290 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/8\n",
      "37/37 [==============================] - 84s 1s/step - loss: 0.3564 - accuracy: 0.8471 - val_loss: 8.5495 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /saved_models/v2-cross-val\\model_1.h5\n",
      "Epoch 2/8\n",
      "37/37 [==============================] - 37s 991ms/step - loss: 0.0333 - accuracy: 0.9920 - val_loss: 0.3925 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.80345, saving model to /saved_models/v2-cross-val\\model_1.h5\n",
      "Epoch 3/8\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.0085 - accuracy: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.80345 to 0.98276, saving model to /saved_models/v2-cross-val\\model_1.h5\n",
      "Epoch 4/8\n",
      "37/37 [==============================] - 54s 1s/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0713 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98276 to 0.98621, saving model to /saved_models/v2-cross-val\\model_1.h5\n",
      "Epoch 5/8\n",
      "37/37 [==============================] - 74s 2s/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.3221 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98621\n",
      "Epoch 6/8\n",
      "37/37 [==============================] - 75s 2s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.2090 - val_accuracy: 0.9034\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98621\n",
      "Epoch 7/8\n",
      "37/37 [==============================] - 73s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0522 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.98621\n",
      "Epoch 8/8\n",
      "37/37 [==============================] - 61s 2s/step - loss: 0.0055 - accuracy: 0.9954 - val_loss: 0.0065 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.98621 to 0.99655, saving model to /saved_models/v2-cross-val\\model_1.h5\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.0065 - accuracy: 0.9966\n",
      "Found 1158 validated image filenames belonging to 2 classes.\n",
      "Found 290 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/8\n",
      "37/37 [==============================] - 82s 1s/step - loss: 0.3416 - accuracy: 0.8418 - val_loss: 20.0908 - val_accuracy: 0.5276\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52759, saving model to /saved_models/v2-cross-val\\model_2.h5\n",
      "Epoch 2/8\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.0516 - accuracy: 0.9862 - val_loss: 0.9360 - val_accuracy: 0.5517\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.52759 to 0.55172, saving model to /saved_models/v2-cross-val\\model_2.h5\n",
      "Epoch 3/8\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 253.4671 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.55172\n",
      "Epoch 4/8\n",
      "37/37 [==============================] - 45s 1s/step - loss: 0.0828 - accuracy: 0.9757 - val_loss: 178.3283 - val_accuracy: 0.5069\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55172\n",
      "Epoch 5/8\n",
      "37/37 [==============================] - 60s 2s/step - loss: 0.0202 - accuracy: 0.9973 - val_loss: 9.1114 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55172 to 0.82069, saving model to /saved_models/v2-cross-val\\model_2.h5\n",
      "Epoch 6/8\n",
      "37/37 [==============================] - 78s 2s/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.8526 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.82069 to 0.93103, saving model to /saved_models/v2-cross-val\\model_2.h5\n",
      "Epoch 7/8\n",
      "37/37 [==============================] - 75s 2s/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 1.8691 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.93103\n",
      "Epoch 8/8\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0119 - accuracy: 0.9997 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.93103 to 0.98621, saving model to /saved_models/v2-cross-val\\model_2.h5\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.0525 - accuracy: 0.9862\n",
      "Found 1158 validated image filenames belonging to 2 classes.\n",
      "Found 290 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/8\n",
      "37/37 [==============================] - 82s 1s/step - loss: 0.3569 - accuracy: 0.8138 - val_loss: 1.6937 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93448, saving model to /saved_models/v2-cross-val\\model_3.h5\n",
      "Epoch 2/8\n",
      "37/37 [==============================] - 47s 1s/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.2861 - val_accuracy: 0.9483\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.93448 to 0.94828, saving model to /saved_models/v2-cross-val\\model_3.h5\n",
      "Epoch 3/8\n",
      "37/37 [==============================] - 47s 1s/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 5.9379 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.94828\n",
      "Epoch 4/8\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0106 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.94828 to 0.99310, saving model to /saved_models/v2-cross-val\\model_3.h5\n",
      "Epoch 5/8\n",
      "37/37 [==============================] - 63s 2s/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0136 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99310\n",
      "Epoch 6/8\n",
      "37/37 [==============================] - 67s 2s/step - loss: 8.1408e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99310\n",
      "Epoch 7/8\n",
      "37/37 [==============================] - 67s 2s/step - loss: 4.4654e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99310\n",
      "Epoch 8/8\n",
      "37/37 [==============================] - 68s 2s/step - loss: 9.7470e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99310\n",
      "10/10 [==============================] - 5s 461ms/step - loss: 0.0106 - accuracy: 0.9931\n",
      "Found 1159 validated image filenames belonging to 2 classes.\n",
      "Found 289 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/8\n",
      "37/37 [==============================] - 86s 1s/step - loss: 0.4221 - accuracy: 0.8144 - val_loss: 38.5592 - val_accuracy: 0.5017\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50173, saving model to /saved_models/v2-cross-val\\model_4.h5\n",
      "Epoch 2/8\n",
      "37/37 [==============================] - 46s 1s/step - loss: 0.0377 - accuracy: 0.9861 - val_loss: 0.8292 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.50173 to 0.88581, saving model to /saved_models/v2-cross-val\\model_4.h5\n",
      "Epoch 3/8\n",
      "37/37 [==============================] - 46s 1s/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.0784 - val_accuracy: 0.9723\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88581 to 0.97232, saving model to /saved_models/v2-cross-val\\model_4.h5\n",
      "Epoch 4/8\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.97232 to 0.99308, saving model to /saved_models/v2-cross-val\\model_4.h5\n",
      "Epoch 5/8\n",
      "37/37 [==============================] - 61s 2s/step - loss: 0.0078 - accuracy: 0.9955 - val_loss: 0.0581 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99308\n",
      "Epoch 6/8\n",
      "37/37 [==============================] - 75s 2s/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 8.7629 - val_accuracy: 0.6055\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99308\n",
      "Epoch 7/8\n",
      "37/37 [==============================] - 76s 2s/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99308 to 1.00000, saving model to /saved_models/v2-cross-val\\model_4.h5\n",
      "Epoch 8/8\n",
      "37/37 [==============================] - 65s 2s/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 5s 443ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Found 1159 validated image filenames belonging to 2 classes.\n",
      "Found 289 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/8\n",
      "37/37 [==============================] - 80s 1s/step - loss: 0.3309 - accuracy: 0.8690 - val_loss: 25.9322 - val_accuracy: 0.3737\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.37370, saving model to /saved_models/v2-cross-val\\model_5.h5\n",
      "Epoch 2/8\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 6.3168 - val_accuracy: 0.4983\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.37370 to 0.49827, saving model to /saved_models/v2-cross-val\\model_5.h5\n",
      "Epoch 3/8\n",
      "37/37 [==============================] - 45s 1s/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 1.5406 - val_accuracy: 0.8097\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.49827 to 0.80969, saving model to /saved_models/v2-cross-val\\model_5.h5\n",
      "Epoch 4/8\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.0296 - accuracy: 0.9879 - val_loss: 0.4898 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80969 to 0.92388, saving model to /saved_models/v2-cross-val\\model_5.h5\n",
      "Epoch 5/8\n",
      "37/37 [==============================] - 67s 2s/step - loss: 0.0379 - accuracy: 0.9909 - val_loss: 0.0724 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.92388 to 0.98616, saving model to /saved_models/v2-cross-val\\model_5.h5\n",
      "Epoch 6/8\n",
      "37/37 [==============================] - 74s 2s/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.3687 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98616\n",
      "Epoch 7/8\n",
      "37/37 [==============================] - 73s 2s/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0630 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.98616\n",
      "Epoch 8/8\n",
      "37/37 [==============================] - 75s 2s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.0661 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98616\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 0.0724 - accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = '/saved_models/v2-cross-val/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_index, val_index in skf.split(np.zeros(len(Y)),Y):\n",
    "\ttraining_data = train_data.iloc[train_index]\n",
    "\tvalidation_data = train_data.iloc[val_index]\n",
    "\t\n",
    "\ttrain_data_generator = idg.flow_from_dataframe(training_data, directory = '../data/archive/', target_size=(224, 224),\n",
    "\t\t\t\t\t\t       x_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t       class_mode = \"binary\", shuffle = True)\n",
    "\tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = '../data/archive/', target_size=(224, 224),\n",
    "\t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t\tclass_mode = \"binary\", shuffle = True)\n",
    "\t\n",
    "\t# CREATE NEW MODEL\n",
    "\tmodel = create_new_model()\n",
    "\t# COMPILE NEW MODEL\n",
    "\tmodel.compile(loss='binary_crossentropy',\n",
    "\t\t      optimizer='Adam',\n",
    "\t\t      metrics=['accuracy'])\n",
    "\t\n",
    "\t# CREATE CALLBACKS\n",
    "\tcheckpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "\t\t\t\t\t\t\tmonitor='val_accuracy', verbose=1, \n",
    "\t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "\tcallbacks_list = [checkpoint]\n",
    "\t# There can be other callbacks, but just showing one because it involves the model name\n",
    "\t# This saves the best model\n",
    "\t# FIT THE MODEL\n",
    "\thistory = model.fit(train_data_generator,\n",
    "\t\t\t    epochs=8,\n",
    "\t\t\t    callbacks=callbacks_list,\n",
    "\t\t\t    validation_data=valid_data_generator)\n",
    "\t#PLOT HISTORY\n",
    "\t#\t\t:\n",
    "\t#\t\t:\n",
    "\t\n",
    "\t# LOAD BEST MODEL to evaluate the performance of the model\n",
    "\tmodel.load_weights(\"/saved_models/v2-cross-val/model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "\tresults = model.evaluate(valid_data_generator)\n",
    "\tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "\tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "\tVALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "\ttf.keras.backend.clear_session()\n",
    "\t\n",
    "\tfold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9924042463302613"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = idg.flow_from_directory(\n",
    "        '../data/test/mouth',  # This is the source directory for training images\n",
    "        target_size=(224, 224),  # All images will be resized to 150x150\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "        batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 996ms/step - loss: 0.2244 - accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22435472905635834, 0.914893627166748]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4298e6fd6da2fe1fbdbe55781d0a378dd9562c1f5795e48e37a7037879961298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
