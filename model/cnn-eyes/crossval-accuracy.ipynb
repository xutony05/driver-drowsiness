{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/archive/cross-val/eyes/eyesLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg  = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuton\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:303: UserWarning: tensorflow.python.keras.applications.inception_resnet_v2 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n"
     ]
    }
   ],
   "source": [
    "#model = keras.models.load_model(\"base_eyes_model.h5\")\n",
    "#model = keras.models.load_model(\"mobile_eyes_model.h5\")\n",
    "model = keras.models.load_model(\"inception_eyes_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_resnet_v2 (Functi  (None, 1, 1, 1536)       54336736  \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1536)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1537      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,338,273\n",
      "Trainable params: 54,277,729\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 291 validated image filenames belonging to 2 classes.\n",
      "10/10 [==============================] - 7s 144ms/step - loss: 4.2734e-04 - accuracy: 1.0000\n",
      "Found 291 validated image filenames belonging to 2 classes.\n",
      "10/10 [==============================] - 2s 149ms/step - loss: 6.1458e-04 - accuracy: 1.0000\n",
      "Found 290 validated image filenames belonging to 2 classes.\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Found 290 validated image filenames belonging to 2 classes.\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 2.0421 - accuracy: 0.9966\n",
      "Found 290 validated image filenames belonging to 2 classes.\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0016 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "for train_index, val_index in skf.split(np.zeros(len(Y)),Y):\n",
    "\tvalidation_data = train_data.iloc[val_index]\n",
    "\t\n",
    "\t# cropped mouth is (80, 80) else (224, 224) \n",
    "\tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = '../data/archive/', target_size=(80, 80),\n",
    "\t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t\tclass_mode = \"binary\", shuffle = True)\n",
    "\t\n",
    "\tresults = model.evaluate(valid_data_generator)\n",
    "\tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "\tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "\tVALIDATION_LOSS.append(results['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984848928451538"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # base eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965564608573914"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # mobile eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993103504180908"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY) # inception eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '../data/test/yourfolderforcroppedeyes',  # This is the source directory for training images\n",
    "        target_size=(80, 80),  # All images will be resized to 150x150\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "        batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 308ms/step - loss: 4.5686e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0004568615404423326, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4298e6fd6da2fe1fbdbe55781d0a378dd9562c1f5795e48e37a7037879961298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
